{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from math import exp\n",
    "import random\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, name, weights, activation, activation_derivative):\n",
    "        self.name = name\n",
    "        self.weights = weights\n",
    "        self.activation = activation\n",
    "        self.activation_derivative = activation_derivative\n",
    "        self.sum = None\n",
    "        self.entry = None\n",
    "\n",
    "    def output(self, entry):\n",
    "        self.entry = [1] + entry\n",
    "        self.sum = reduce(lambda a, b: a + b, map(lambda x, y: x*y, self.entry, self.weights))\n",
    "        return self.activation(self.sum)\n",
    "\n",
    "    def update_weights(self, error, alpha):\n",
    "        lerr = self.activation_derivative(self.sum) * error\n",
    "        for idx, _ in enumerate(self.weights):\n",
    "            delta = lerr * self.entry[idx]\n",
    "            self.weights[idx] += - delta * alpha\n",
    "        return lerr\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def output(self, entry):\n",
    "        for layer in self.layers:\n",
    "            entry = [neuron.output(entry) for neuron in layer]\n",
    "        return entry[0]\n",
    "\n",
    "    def update_weights(self, error, alpha):\n",
    "        for lidx, layer in enumerate(reversed(self.layers)):\n",
    "            lerror = error[lidx]\n",
    "            new_error = []\n",
    "            for idx, neuron in enumerate(layer):\n",
    "                err = neuron.update_weights(lerror[idx], alpha)\n",
    "                new_error.append([err * weight for weight in neuron.weights[1:]])\n",
    "            error += new_error\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + exp(-x))\n",
    "def sigmoid_derivative(x):\n",
    "    return exp(-x) / (1 + exp(-x))**2\n",
    "\n",
    "n1_l1 = Neuron('or', [-1, 10, 10], sigmoid, sigmoid_derivative)\n",
    "n2_l1 = Neuron('nand', [1, -0.5, -0.5], sigmoid, sigmoid_derivative)\n",
    "n1_l2 = Neuron('and', [-1, 1, 1], sigmoid, sigmoid_derivative)\n",
    "\n",
    "layer1, layer2 = [n1_l1, n2_l1], [n1_l2]\n",
    "\n",
    "network = Network([layer1, layer2])\n",
    "\n",
    "train_set = {\"0x0\": ([1, 0, 0], 0), \"0x1\": ([1, 0, 1], 1),\n",
    "             \"1x0\": ([1, 1, 0], 1), \"1x1\": ([1, 1, 1], 0)}\n",
    "\n",
    "for i in range(0, 100000):\n",
    "    key = random.choice(list(train_set.keys()))\n",
    "    inpt, real = train_set[key]\n",
    "    pred = network.output(inpt)\n",
    "    network.update_weights([[2 * (pred - real)]], 0.1)\n",
    "\n",
    "for key, values in train_set.items():\n",
    "    inpt, real = values\n",
    "    pred = network.output(inpt)\n",
    "    print(key, real, pred)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
