{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2427b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from math import exp\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, name, weights, activation):\n",
    "        self.name = name\n",
    "        self.weights = weights\n",
    "        self.activation = activation\n",
    "        self.sum = None\n",
    "        self.entry = None\n",
    "\n",
    "    def output(self, entry):\n",
    "        self.entry = entry\n",
    "        sum = reduce(lambda a, b : a + b,\n",
    "                     [self.weights[i] * entry[i] for i in range(0, len(entry))])\n",
    "        self.sum =  sum\n",
    "        return self.activation(sum)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name + \": \" + str(self.weights)\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def output(self, entry):\n",
    "        for layer in self.layers:\n",
    "            new_entry = [1.] # biais\n",
    "            for neuron in layer:\n",
    "                out = neuron.output(entry)\n",
    "                new_entry.append(out)\n",
    "            entry = new_entry\n",
    "        return out\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + exp(-x))\n",
    "\n",
    "n1_l1 = Neuron(\"n1_l1\", [-4, 10, 10], sigmoid) # or\n",
    "n2_l1 = Neuron(\"n2_l1\", [9, -6, -6], sigmoid) # nand\n",
    "n1_l2 = Neuron(\"n1_l2\", [-16, 10, 10], sigmoid) # and\n",
    "\n",
    "layer1 = [n1_l1, n2_l1]\n",
    "layer2 = [n1_l2]\n",
    "\n",
    "network = Network([layer1, layer2])\n",
    "\n",
    "print(network.output([1, 0, 1]))\n",
    "# > 0.9707166363167491\n",
    "print(network.output([1, 1, 0]))\n",
    "# > 0.9707166363167491\n",
    "print(network.output([1, 0, 0]))\n",
    "# > 0.002954780238219401\n",
    "print(network.output([1, 1, 1]))\n",
    "# > 0.002954780238219401"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
